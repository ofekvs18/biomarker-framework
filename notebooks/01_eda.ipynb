{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Exploratory Data Analysis\n",
    "\n",
    "This notebook performs initial exploration of MIMIC-IV data for biomarker discovery.\n",
    "\n",
    "## Objectives\n",
    "1. Load and inspect MIMIC-IV tables\n",
    "2. Explore CBC lab values distribution\n",
    "3. Analyze disease prevalence\n",
    "4. Identify data quality issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Set paths\nDATA_DIR = Path('../data/raw')\nCONFIG_DIR = Path('../configs')\n\nprint(f\"Data directory: {DATA_DIR}\")\nprint(f\"Data directory exists: {DATA_DIR.exists()}\")\n\n# List available data files\nif DATA_DIR.exists():\n    parquet_files = list(DATA_DIR.glob(\"*.parquet\"))\n    if parquet_files:\n        print(f\"\\nAvailable parquet files ({len(parquet_files)}):\")\n        for f in parquet_files:\n            size_mb = f.stat().st_size / (1024 ** 2)\n            print(f\"  - {f.name:30s} ({size_mb:>8.1f} MB)\")\n    else:\n        print(\"\\n⚠️  No parquet files found!\")\n        print(\"\\nTo download MIMIC-IV data, run:\")\n        print(\"  python scripts/download_mimic_from_bigquery.py --output-dir ../mimic_data\")\n        print(\"\\nExpected files:\")\n        expected_files = [\n            'patients.parquet',\n            'admissions.parquet', \n            'icustays.parquet',\n            'diagnoses_icd.parquet',\n            'd_icd_diagnoses.parquet',\n            'labevents.parquet',\n            'd_labitems.parquet'\n        ]\n        for fname in expected_files:\n            print(f\"  - {fname}\")\nelse:\n    print(f\"\\n⚠️  Data directory does not exist: {DATA_DIR}\")\n\n# Flag to check if we can proceed with data loading\nDATA_AVAILABLE = DATA_DIR.exists() and len(list(DATA_DIR.glob(\"*.parquet\"))) > 0\nprint(f\"\\nData available for analysis: {DATA_AVAILABLE}\")"
  },
  {
   "cell_type": "markdown",
   "source": "## MIMIC-IV Data Structure Overview\n\n### Available Tables\n\nThis analysis is based on the MIMIC-IV dataset structure. The following tables are expected in `data/raw/`:\n\n1. **patients.parquet** - Patient demographics\n2. **admissions.parquet** - Hospital admission records  \n3. **icustays.parquet** - ICU stay records\n4. **diagnoses_icd.parquet** - ICD diagnosis codes per admission\n5. **d_icd_diagnoses.parquet** - ICD code descriptions (lookup table)\n6. **labevents.parquet** - Laboratory test results (including CBC)\n7. **d_labitems.parquet** - Lab test catalog (lookup table)\n\n### Table Schemas\n\n#### 1. patients.parquet\nPrimary patient demographics table.\n\n| Column | Type | Description |\n|--------|------|-------------|\n| subject_id | int | **PRIMARY KEY** - Unique patient identifier |\n| gender | str | Patient gender (M/F) |\n| anchor_age | int | Age at anchor_year |\n| anchor_year | int | Shifted year for de-identification |\n| anchor_year_group | str | Year range group |\n| dod | datetime | Date of death (if applicable) |\n\n**Rows:** ~300,000 unique patients\n\n---\n\n#### 2. admissions.parquet  \nHospital admission records with demographics and outcome.\n\n| Column | Type | Description |\n|--------|------|-------------|\n| subject_id | int | **FOREIGN KEY** → patients.subject_id |\n| hadm_id | int | **PRIMARY KEY** - Hospital admission ID |\n| admittime | datetime | Admission timestamp |\n| dischtime | datetime | Discharge timestamp |\n| deathtime | datetime | Death time (if died during admission) |\n| admission_type | str | Type (e.g., EMERGENCY, ELECTIVE) |\n| admission_location | str | Where admitted from |\n| discharge_location | str | Where discharged to |\n| insurance | str | Insurance type |\n| language | str | Primary language |\n| marital_status | str | Marital status |\n| race | str | Race/ethnicity |\n| hospital_expire_flag | int | 1 if died in hospital, 0 otherwise |\n\n**Rows:** ~500,000 admissions\n\n---\n\n#### 3. icustays.parquet\nICU stay records (subset of admissions that included ICU care).\n\n| Column | Type | Description |\n|--------|------|-------------|\n| subject_id | int | **FOREIGN KEY** → patients.subject_id |\n| hadm_id | int | **FOREIGN KEY** → admissions.hadm_id |\n| stay_id | int | **PRIMARY KEY** - ICU stay identifier |\n| first_careunit | str | First ICU care unit |\n| last_careunit | str | Last ICU care unit |\n| intime | datetime | ICU admission time |\n| outtime | datetime | ICU discharge time |\n| los | float | Length of stay (days) |\n\n**Rows:** ~70,000 ICU stays\n\n---\n\n#### 4. diagnoses_icd.parquet\nICD diagnosis codes for each hospital admission.\n\n| Column | Type | Description |\n|--------|------|-------------|\n| subject_id | int | **FOREIGN KEY** → patients.subject_id |\n| hadm_id | int | **FOREIGN KEY** → admissions.hadm_id |\n| seq_num | int | Diagnosis sequence number (priority) |\n| icd_code | str | ICD diagnosis code |\n| icd_version | int | 9 (ICD-9) or 10 (ICD-10) |\n\n**Rows:** ~5,000,000 diagnosis records  \n**Note:** Each admission can have multiple diagnoses (seq_num orders by priority)\n\n---\n\n#### 5. d_icd_diagnoses.parquet\nICD code descriptions (lookup/reference table).\n\n| Column | Type | Description |\n|--------|------|-------------|\n| icd_code | str | **PRIMARY KEY** - ICD code |\n| icd_version | int | 9 or 10 |\n| long_title | str | Full description of diagnosis |\n\n**Rows:** ~100,000 unique codes  \n**Purpose:** Joins with diagnoses_icd to get human-readable diagnosis names\n\n---\n\n#### 6. labevents.parquet ⚠️ LARGE TABLE\nLaboratory test results including all blood tests (CBC, chemistry, etc.).\n\n| Column | Type | Description |\n|--------|------|-------------|\n| labevent_id | int | **PRIMARY KEY** - Unique lab event ID |\n| subject_id | int | **FOREIGN KEY** → patients.subject_id |\n| hadm_id | int | **FOREIGN KEY** → admissions.hadm_id |\n| specimen_id | int | Specimen identifier |\n| itemid | int | **FOREIGN KEY** → d_labitems.itemid |\n| charttime | datetime | When lab was charted |\n| storetime | datetime | When lab was stored |\n| value | str | Lab result as string |\n| valuenum | float | Lab result as numeric value |\n| valueuom | str | Unit of measurement (e.g., 'g/dL', 'K/uL') |\n| ref_range_lower | float | Reference range lower bound |\n| ref_range_upper | float | Reference range upper bound |\n| flag | str | Abnormal flag indicator |\n| priority | str | Test priority (ROUTINE, STAT, etc.) |\n| comments | str | Additional comments |\n\n**Rows:** 100,000,000+ lab events (very large!)  \n**Note:** Filtered to only numeric values (valuenum IS NOT NULL) during download\n\n---\n\n#### 7. d_labitems.parquet\nLab test catalog/definitions (lookup table).\n\n| Column | Type | Description |\n|--------|------|-------------|\n| itemid | int | **PRIMARY KEY** - Lab item identifier |\n| label | str | Lab test name (e.g., \"Hemoglobin\", \"Glucose\") |\n| fluid | str | Specimen fluid (e.g., \"Blood\", \"Urine\") |\n| category | str | Test category (e.g., \"Hematology\", \"Chemistry\") |\n\n**Rows:** ~1,500 unique lab tests  \n**Purpose:** Joins with labevents to get test names and categories\n\n---\n\n### Table Relationships\n\n```\npatients (subject_id)\n    │\n    ├──► admissions (subject_id, hadm_id)\n    │        │\n    │        ├──► icustays (hadm_id, stay_id)\n    │        │\n    │        ├──► diagnoses_icd (hadm_id, icd_code)\n    │        │        │\n    │        │        └──► d_icd_diagnoses (icd_code) [lookup]\n    │        │\n    │        └──► labevents (hadm_id, itemid)\n    │                 │\n    │                 └──► d_labitems (itemid) [lookup]\n    │\n    └──► labevents (subject_id)\n```\n\n### Key Relationships Summary\n\n| Join | Primary Table | Foreign Table | Join Columns | Purpose |\n|------|--------------|---------------|--------------|---------|\n| 1 | patients | admissions | subject_id | Get patient demographics for admission |\n| 2 | admissions | icustays | hadm_id | Find ICU stays for admission |\n| 3 | admissions | diagnoses_icd | hadm_id | Get diagnoses for admission |\n| 4 | diagnoses_icd | d_icd_diagnoses | icd_code, icd_version | Get diagnosis descriptions |\n| 5 | admissions | labevents | hadm_id | Get lab results for admission |\n| 6 | labevents | d_labitems | itemid | Get lab test name/category |\n| 7 | patients | labevents | subject_id | Get all labs for a patient |\n\n---\n\n### Answers to Key Questions\n\n#### Q1: Where are the CBC test results?\n**Answer:** CBC (Complete Blood Count) test results are in `labevents.parquet`.  \n\n- Each CBC component (WBC, RBC, Hemoglobin, Hematocrit, Platelets, etc.) has specific `itemid` values\n- The `configs/cbc_features.yaml` file maps CBC feature names to their corresponding itemids\n- Join `labevents` with `d_labitems` on `itemid` to get the human-readable test name\n\n#### Q2: Are there labevents.parquet or chartevents.parquet files?\n**Answer:** Yes, `labevents.parquet` exists and contains all laboratory test results.  \n\n- `chartevents.parquet` is NOT included in this pipeline (it contains vital signs, not lab tests)\n- All blood tests including CBC are in `labevents.parquet`\n\n#### Q3: How are lab tests linked to admissions?\n**Answer:** Via the `hadm_id` (hospital admission ID) column.\n\n- Each row in `labevents` has a `hadm_id` that links to `admissions.hadm_id`\n- This allows you to:\n  - Find all labs for a specific admission\n  - Link lab results to patient demographics, diagnoses, and outcomes\n  - Filter labs to specific time windows relative to admission\n\n**Example join:**\n```python\n# Get all CBC results for a specific admission\nadmission_labs = labevents[labevents['hadm_id'] == specific_hadm_id]\n\n# Or join to get admission details with labs\nlabs_with_admission = labevents.merge(\n    admissions[['hadm_id', 'subject_id', 'admittime', 'dischtime']], \n    on='hadm_id', \n    how='left'\n)\n```",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": "## Sample Data Extraction Queries\n\nBelow are common query patterns for extracting biomarker data from MIMIC-IV tables.\n\n### Query 1: Get All CBC Results for a Patient\n\n```python\n# Get all CBC lab results for a specific patient\ndef get_patient_cbc_labs(subject_id, labevents, d_labitems, cbc_itemids):\n    \"\"\"\n    Extract all CBC measurements for a patient\n    \n    Args:\n        subject_id: Patient identifier\n        labevents: Lab events DataFrame\n        d_labitems: Lab items lookup DataFrame\n        cbc_itemids: List of CBC test item IDs\n    \n    Returns:\n        DataFrame with CBC results\n    \"\"\"\n    # Filter to CBC tests for this patient\n    patient_cbc = labevents[\n        (labevents['subject_id'] == subject_id) & \n        (labevents['itemid'].isin(cbc_itemids))\n    ].copy()\n    \n    # Join with lab names\n    patient_cbc = patient_cbc.merge(\n        d_labitems[['itemid', 'label']], \n        on='itemid', \n        how='left'\n    )\n    \n    return patient_cbc[['charttime', 'label', 'valuenum', 'valueuom', 'ref_range_lower', 'ref_range_upper']]\n```\n\n### Query 2: Link Admissions to Diagnoses\n\n```python\n# Get all diagnoses for admissions with human-readable descriptions\ndef get_admission_diagnoses(admissions, diagnoses_icd, d_icd_diagnoses):\n    \"\"\"\n    Get all diagnoses for hospital admissions with descriptions\n    \n    Returns:\n        DataFrame with admission ID, ICD code, and diagnosis description\n    \"\"\"\n    # Join diagnoses with descriptions\n    diagnoses_with_desc = diagnoses_icd.merge(\n        d_icd_diagnoses[['icd_code', 'icd_version', 'long_title']], \n        on=['icd_code', 'icd_version'], \n        how='left'\n    )\n    \n    # Join with admissions to get admission details\n    admission_diagnoses = diagnoses_with_desc.merge(\n        admissions[['hadm_id', 'subject_id', 'admittime', 'dischtime']], \n        on='hadm_id', \n        how='left'\n    )\n    \n    return admission_diagnoses.sort_values(['hadm_id', 'seq_num'])\n```\n\n### Query 3: Find Patients with Specific Disease\n\n```python\n# Find all patients diagnosed with sepsis (ICD-10: A41.x or ICD-9: 038.x)\ndef find_patients_with_disease(icd_prefixes, diagnoses_icd):\n    \"\"\"\n    Find patients diagnosed with specific disease codes\n    \n    Args:\n        icd_prefixes: List of ICD code prefixes (e.g., ['A41', '038'])\n        diagnoses_icd: Diagnoses DataFrame\n    \n    Returns:\n        List of unique subject_ids\n    \"\"\"\n    # Create mask for any ICD code matching the prefixes\n    mask = diagnoses_icd['icd_code'].str.startswith(tuple(icd_prefixes))\n    \n    # Get unique patients\n    patient_ids = diagnoses_icd[mask]['subject_id'].unique()\n    \n    return patient_ids\n\n# Example: Find sepsis patients\nsepsis_patients = find_patients_with_disease(['A41', '038'], diagnoses_icd)\nprint(f\"Found {len(sepsis_patients)} patients with sepsis\")\n```\n\n### Query 4: CBC Values at Admission Time\n\n```python\n# Get CBC values within first 24 hours of admission\ndef get_admission_cbc(hadm_id, admissions, labevents, cbc_itemids, hours_window=24):\n    \"\"\"\n    Get CBC values near admission time\n    \n    Args:\n        hadm_id: Hospital admission ID\n        admissions: Admissions DataFrame\n        labevents: Lab events DataFrame\n        cbc_itemids: List of CBC test item IDs\n        hours_window: Time window after admission (default: 24 hours)\n    \n    Returns:\n        DataFrame with CBC results within time window\n    \"\"\"\n    # Get admission time\n    admission = admissions[admissions['hadm_id'] == hadm_id].iloc[0]\n    admit_time = admission['admittime']\n    \n    # Get labs for this admission\n    admission_labs = labevents[\n        (labevents['hadm_id'] == hadm_id) &\n        (labevents['itemid'].isin(cbc_itemids))\n    ].copy()\n    \n    # Filter to time window\n    admission_labs['hours_since_admit'] = (\n        (admission_labs['charttime'] - admit_time).dt.total_seconds() / 3600\n    )\n    \n    early_labs = admission_labs[\n        (admission_labs['hours_since_admit'] >= 0) &\n        (admission_labs['hours_since_admit'] <= hours_window)\n    ]\n    \n    return early_labs\n```\n\n### Query 5: Build Patient-Level Feature Matrix\n\n```python\n# Aggregate CBC values per patient for predictive modeling\ndef build_patient_features(subject_ids, labevents, admissions, diagnoses_icd, \n                          cbc_itemids, target_icd_codes):\n    \"\"\"\n    Build patient-level feature matrix with:\n    - Aggregated CBC values (mean, std, min, max)\n    - Demographics\n    - Target disease label\n    \n    Args:\n        subject_ids: List of patient IDs\n        labevents: Lab events DataFrame\n        admissions: Admissions DataFrame\n        diagnoses_icd: Diagnoses DataFrame\n        cbc_itemids: List of CBC test item IDs\n        target_icd_codes: List of ICD codes for target disease\n    \n    Returns:\n        DataFrame with one row per patient\n    \"\"\"\n    patient_features = []\n    \n    for subject_id in subject_ids:\n        # Get CBC labs\n        patient_labs = labevents[\n            (labevents['subject_id'] == subject_id) &\n            (labevents['itemid'].isin(cbc_itemids))\n        ]\n        \n        # Aggregate by itemid\n        cbc_stats = patient_labs.groupby('itemid')['valuenum'].agg([\n            'mean', 'std', 'min', 'max', 'count'\n        ]).add_prefix('cbc_')\n        \n        # Get target label\n        patient_diagnoses = diagnoses_icd[diagnoses_icd['subject_id'] == subject_id]\n        has_disease = patient_diagnoses['icd_code'].str.startswith(\n            tuple(target_icd_codes)\n        ).any()\n        \n        # Combine features\n        features = {\n            'subject_id': subject_id,\n            'has_disease': int(has_disease),\n            **cbc_stats.to_dict('records')[0] if len(cbc_stats) > 0 else {}\n        }\n        \n        patient_features.append(features)\n    \n    return pd.DataFrame(patient_features)\n```\n\n### Query 6: Join Everything Together\n\n```python\n# Create comprehensive patient-admission-labs dataset\ndef create_full_dataset(patients, admissions, labevents, diagnoses_icd, \n                       d_labitems, d_icd_diagnoses):\n    \"\"\"\n    Create a complete dataset joining all tables\n    \n    Returns:\n        DataFrame with patient demographics, admission details, lab results, and diagnoses\n    \"\"\"\n    # Start with labs\n    data = labevents.copy()\n    \n    # Add lab test names\n    data = data.merge(\n        d_labitems[['itemid', 'label', 'category']], \n        on='itemid', \n        how='left'\n    )\n    \n    # Add admission details\n    data = data.merge(\n        admissions[['hadm_id', 'subject_id', 'admittime', 'dischtime', \n                   'admission_type', 'hospital_expire_flag']], \n        on=['hadm_id', 'subject_id'], \n        how='left'\n    )\n    \n    # Add patient demographics\n    data = data.merge(\n        patients[['subject_id', 'gender', 'anchor_age']], \n        on='subject_id', \n        how='left'\n    )\n    \n    # Add primary diagnosis (seq_num = 1)\n    primary_dx = diagnoses_icd[diagnoses_icd['seq_num'] == 1].copy()\n    primary_dx = primary_dx.merge(\n        d_icd_diagnoses[['icd_code', 'icd_version', 'long_title']], \n        on=['icd_code', 'icd_version'], \n        how='left'\n    )\n    \n    data = data.merge(\n        primary_dx[['hadm_id', 'icd_code', 'long_title']], \n        on='hadm_id', \n        how='left',\n        suffixes=('', '_primary_dx')\n    )\n    \n    return data\n```",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Configuration Files"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "# Load patients\nif DATA_AVAILABLE:\n    if (DATA_DIR / 'patients.parquet').exists():\n        patients = pd.read_parquet(DATA_DIR / 'patients.parquet')\n        print(f\"Patients: {len(patients):,} rows × {len(patients.columns)} columns\")\n        print(f\"\\nColumns: {list(patients.columns)}\")\n        print(f\"\\nData types:\")\n        print(patients.dtypes)\n        print(f\"\\nFirst few rows:\")\n        display(patients.head())\n        print(f\"\\nSummary statistics:\")\n        display(patients.describe())\n    else:\n        print(\"⚠️  patients.parquet not found\")\nelse:\n    print(\"⚠️  Data not available. See instructions above to download MIMIC-IV data.\")",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load admissions\nif DATA_AVAILABLE:\n    if (DATA_DIR / 'admissions.parquet').exists():\n        admissions = pd.read_parquet(DATA_DIR / 'admissions.parquet')\n        print(f\"Admissions: {len(admissions):,} rows × {len(admissions.columns)} columns\")\n        print(f\"\\nColumns: {list(admissions.columns)}\")\n        print(f\"\\nData types:\")\n        print(admissions.dtypes)\n        print(f\"\\nFirst few rows:\")\n        display(admissions.head())\n        print(f\"\\nAdmission types:\")\n        display(admissions['admission_type'].value_counts())\n    else:\n        print(\"⚠️  admissions.parquet not found\")\nelse:\n    print(\"⚠️  Data not available.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Load diagnoses\nif DATA_AVAILABLE:\n    if (DATA_DIR / 'diagnoses_icd.parquet').exists():\n        diagnoses = pd.read_parquet(DATA_DIR / 'diagnoses_icd.parquet')\n        print(f\"Diagnoses: {len(diagnoses):,} rows × {len(diagnoses.columns)} columns\")\n        print(f\"\\nColumns: {list(diagnoses.columns)}\")\n        print(f\"\\nData types:\")\n        print(diagnoses.dtypes)\n        print(f\"\\nICD version distribution:\")\n        display(diagnoses['icd_version'].value_counts())\n        print(f\"\\nFirst few rows:\")\n        display(diagnoses.head())\n    else:\n        print(\"⚠️  diagnoses_icd.parquet not found\")\nelse:\n    print(\"⚠️  Data not available.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load lab items dictionary\nif DATA_AVAILABLE:\n    if (DATA_DIR / 'd_labitems.parquet').exists():\n        d_labitems = pd.read_parquet(DATA_DIR / 'd_labitems.parquet')\n        print(f\"Lab items: {len(d_labitems):,} rows × {len(d_labitems.columns)} columns\")\n        print(f\"\\nColumns: {list(d_labitems.columns)}\")\n        print(f\"\\nCategories:\")\n        display(d_labitems['category'].value_counts())\n        print(f\"\\nFirst 10 rows:\")\n        display(d_labitems.head(10))\n    else:\n        print(\"⚠️  d_labitems.parquet not found\")\nelse:\n    print(\"⚠️  Data not available.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load lab events (may take a moment - large file)\nif DATA_AVAILABLE:\n    if (DATA_DIR / 'labevents.parquet').exists():\n        print(\"Loading labevents (this may take a moment for large files)...\")\n        labevents = pd.read_parquet(DATA_DIR / 'labevents.parquet')\n        print(f\"Lab events: {len(labevents):,} rows × {len(labevents.columns)} columns\")\n        print(f\"\\nColumns: {list(labevents.columns)}\")\n        print(f\"\\nData types:\")\n        print(labevents.dtypes)\n        print(f\"\\nMemory usage: {labevents.memory_usage(deep=True).sum() / 1024**3:.2f} GB\")\n        print(f\"\\nFirst few rows:\")\n        display(labevents.head())\n        print(f\"\\nSummary of numeric values:\")\n        display(labevents['valuenum'].describe())\n    else:\n        print(\"⚠️  labevents.parquet not found\")\nelse:\n    print(\"⚠️  Data not available.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load diagnoses\n",
    "diagnoses = pd.read_parquet(DATA_DIR / 'diagnoses_icd.parquet')\n",
    "print(f\"Diagnoses: {len(diagnoses):,} rows\")\n",
    "diagnoses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Get CBC itemids from config\nif DATA_AVAILABLE:\n    cbc_itemids = []\n    itemid_to_name = {}\n\n    for feature_name, feature_info in cbc_config['cbc_features'].items():\n        for itemid in feature_info['itemids']:\n            cbc_itemids.append(itemid)\n            itemid_to_name[itemid] = feature_name\n\n    print(f\"Total CBC itemids: {len(cbc_itemids)}\")\n    print(f\"\\nCBC features mapped:\")\n    for feature_name, feature_info in cbc_config['cbc_features'].items():\n        itemids = feature_info['itemids']\n        print(f\"  {feature_name:20s} → itemids: {itemids}\")\nelse:\n    print(\"⚠️  Data not available.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Filter to CBC labs only\nif DATA_AVAILABLE and 'labevents' in dir():\n    cbc_labs = labevents[labevents['itemid'].isin(cbc_itemids)].copy()\n    cbc_labs['feature_name'] = cbc_labs['itemid'].map(itemid_to_name)\n\n    print(f\"Total lab events: {len(labevents):,}\")\n    print(f\"CBC lab events: {len(cbc_labs):,} ({100*len(cbc_labs)/len(labevents):.2f}%)\")\n    print(f\"\\nCBC features found:\")\n    print(cbc_labs['feature_name'].value_counts())\n    print(f\"\\nFirst few CBC lab results:\")\n    display(cbc_labs.head(10))\nelse:\n    print(\"⚠️  Data not available.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Summary statistics per CBC feature\nif DATA_AVAILABLE and 'cbc_labs' in dir():\n    cbc_summary = cbc_labs.groupby('feature_name')['valuenum'].describe()\n    print(\"CBC Feature Summary Statistics:\")\n    display(cbc_summary)\n    \n    print(\"\\n\\nCBC value ranges vs reference ranges from config:\")\n    for feature_name in cbc_labs['feature_name'].unique():\n        if pd.notna(feature_name) and feature_name in cbc_config['cbc_features']:\n            feature_data = cbc_labs[cbc_labs['feature_name'] == feature_name]['valuenum']\n            ref_range = cbc_config['cbc_features'][feature_name].get('reference_range', {})\n            \n            print(f\"\\n{feature_name}:\")\n            print(f\"  Observed: {feature_data.min():.2f} - {feature_data.max():.2f}\")\n            print(f\"  Reference: {ref_range.get('low', 'N/A')} - {ref_range.get('high', 'N/A')}\")\n            print(f\"  Mean: {feature_data.mean():.2f}, Median: {feature_data.median():.2f}\")\nelse:\n    print(\"⚠️  Data not available.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Plot distributions\nif DATA_AVAILABLE and 'cbc_labs' in dir():\n    # Create output directory if needed\n    import os\n    os.makedirs('../experiments', exist_ok=True)\n    \n    unique_features = cbc_labs['feature_name'].dropna().unique()\n    n_features = len(unique_features)\n    \n    # Calculate grid size\n    n_cols = 4\n    n_rows = (n_features + n_cols - 1) // n_cols\n    \n    fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, n_rows * 3))\n    axes = axes.flatten() if n_rows > 1 else [axes]\n    \n    for idx, feature_name in enumerate(unique_features):\n        data = cbc_labs[cbc_labs['feature_name'] == feature_name]['valuenum'].dropna()\n        \n        # Get reference range from config\n        if feature_name in cbc_config['cbc_features']:\n            ref_range = cbc_config['cbc_features'][feature_name].get('reference_range', {})\n            low = ref_range.get('low')\n            high = ref_range.get('high')\n        else:\n            low, high = None, None\n        \n        ax = axes[idx]\n        \n        # Plot histogram\n        ax.hist(data, bins=50, edgecolor='black', alpha=0.7, color='skyblue')\n        ax.set_title(f'{feature_name}\\n(n={len(data):,})', fontsize=10)\n        ax.set_xlabel('Value', fontsize=9)\n        ax.set_ylabel('Count', fontsize=9)\n        \n        # Add reference range lines\n        if low is not None:\n            ax.axvline(low, color='red', linestyle='--', linewidth=2, label=f'Low: {low}')\n        if high is not None:\n            ax.axvline(high, color='red', linestyle='--', linewidth=2, label=f'High: {high}')\n        \n        if low is not None or high is not None:\n            ax.legend(fontsize=7)\n        \n        # Format axis\n        ax.tick_params(labelsize=8)\n    \n    # Hide empty subplots\n    for idx in range(n_features, len(axes)):\n        axes[idx].set_visible(False)\n    \n    plt.tight_layout()\n    plt.savefig('../experiments/cbc_distributions.png', dpi=150, bbox_inches='tight')\n    print(\"Saved plot to ../experiments/cbc_distributions.png\")\n    plt.show()\nelse:\n    print(\"⚠️  Data not available.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to CBC labs only\n",
    "cbc_labs = labevents[labevents['itemid'].isin(cbc_itemids)].copy()\n",
    "cbc_labs['feature_name'] = cbc_labs['itemid'].map(itemid_to_name)\n",
    "\n",
    "print(f\"CBC lab events: {len(cbc_labs):,} rows\")\n",
    "cbc_labs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Count patients per disease\nif DATA_AVAILABLE and 'diagnoses' in dir():\n    disease_counts = {}\n\n    for disease_name, disease_info in diseases_config['diseases'].items():\n        icd_codes = disease_info.get('icd9_codes', []) + disease_info.get('icd10_codes', [])\n        \n        # Match patients with these ICD codes\n        mask = diagnoses['icd_code'].str.startswith(tuple(icd_codes))\n        patient_count = diagnoses[mask]['subject_id'].nunique()\n        admission_count = diagnoses[mask]['hadm_id'].nunique()\n        \n        disease_counts[disease_name] = {\n            'patients': patient_count,\n            'admissions': admission_count,\n            'icd_codes': icd_codes\n        }\n\n    disease_df = pd.DataFrame({\n        'disease': disease_counts.keys(),\n        'patient_count': [v['patients'] for v in disease_counts.values()],\n        'admission_count': [v['admissions'] for v in disease_counts.values()]\n    }).sort_values('patient_count', ascending=False)\n\n    print(\"Disease Prevalence in Dataset:\")\n    display(disease_df)\n    \n    print(\"\\n\\nDetailed breakdown:\")\n    for disease_name, info in disease_counts.items():\n        print(f\"\\n{disease_name}:\")\n        print(f\"  Patients: {info['patients']:,}\")\n        print(f\"  Admissions: {info['admissions']:,}\")\n        print(f\"  ICD codes: {info['icd_codes']}\")\nelse:\n    print(\"⚠️  Data not available.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Plot disease prevalence\nif DATA_AVAILABLE and 'disease_df' in dir():\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n    \n    # Plot patient counts\n    ax1.barh(disease_df['disease'], disease_df['patient_count'], color='steelblue')\n    ax1.set_xlabel('Number of Unique Patients', fontsize=12)\n    ax1.set_ylabel('Disease', fontsize=12)\n    ax1.set_title('Disease Prevalence by Patient Count', fontsize=14, fontweight='bold')\n    ax1.grid(axis='x', alpha=0.3)\n    \n    # Add value labels\n    for i, v in enumerate(disease_df['patient_count']):\n        ax1.text(v, i, f' {v:,}', va='center', fontsize=10)\n    \n    # Plot admission counts\n    ax2.barh(disease_df['disease'], disease_df['admission_count'], color='coral')\n    ax2.set_xlabel('Number of Admissions', fontsize=12)\n    ax2.set_ylabel('Disease', fontsize=12)\n    ax2.set_title('Disease Prevalence by Admission Count', fontsize=14, fontweight='bold')\n    ax2.grid(axis='x', alpha=0.3)\n    \n    # Add value labels\n    for i, v in enumerate(disease_df['admission_count']):\n        ax2.text(v, i, f' {v:,}', va='center', fontsize=10)\n    \n    plt.tight_layout()\n    plt.savefig('../experiments/disease_prevalence.png', dpi=150, bbox_inches='tight')\n    print(\"Saved plot to ../experiments/disease_prevalence.png\")\n    plt.show()\nelse:\n    print(\"⚠️  Data not available.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Disease Prevalence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Check for missing values\nif DATA_AVAILABLE and 'cbc_labs' in dir():\n    print(\"Missing values in CBC labs:\")\n    missing = cbc_labs.isnull().sum()\n    missing_pct = 100 * missing / len(cbc_labs)\n    \n    missing_df = pd.DataFrame({\n        'column': missing.index,\n        'missing_count': missing.values,\n        'missing_pct': missing_pct.values\n    }).sort_values('missing_count', ascending=False)\n    \n    display(missing_df[missing_df['missing_count'] > 0])\n    \n    print(f\"\\n\\nTotal CBC lab rows: {len(cbc_labs):,}\")\n    print(f\"Rows with missing valuenum: {cbc_labs['valuenum'].isnull().sum():,}\")\nelse:\n    print(\"⚠️  Data not available.\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Check for outliers\nif DATA_AVAILABLE and 'cbc_labs' in dir():\n    print(\"Potential outliers (beyond 3 standard deviations):\")\n    print(\"-\" * 80)\n    \n    outlier_summary = []\n    \n    for feature in sorted(cbc_labs['feature_name'].dropna().unique()):\n        data = cbc_labs[cbc_labs['feature_name'] == feature]['valuenum'].dropna()\n        \n        if len(data) > 0:\n            mean, std = data.mean(), data.std()\n            median = data.median()\n            \n            # Count outliers beyond 3 std\n            lower_bound = mean - 3*std\n            upper_bound = mean + 3*std\n            outliers = ((data < lower_bound) | (data > upper_bound)).sum()\n            pct = 100 * outliers / len(data)\n            \n            # Also check using IQR method\n            q1, q3 = data.quantile(0.25), data.quantile(0.75)\n            iqr = q3 - q1\n            iqr_lower = q1 - 1.5*iqr\n            iqr_upper = q3 + 1.5*iqr\n            iqr_outliers = ((data < iqr_lower) | (data > iqr_upper)).sum()\n            iqr_pct = 100 * iqr_outliers / len(data)\n            \n            outlier_summary.append({\n                'feature': feature,\n                'n': len(data),\n                'mean': mean,\n                'median': median,\n                'std': std,\n                '3std_outliers': outliers,\n                '3std_pct': pct,\n                'iqr_outliers': iqr_outliers,\n                'iqr_pct': iqr_pct\n            })\n            \n            print(f\"{feature:20s} | n={len(data):>8,} | 3σ outliers: {outliers:>7,} ({pct:>5.2f}%) | IQR outliers: {iqr_outliers:>7,} ({iqr_pct:>5.2f}%)\")\n    \n    print(\"\\n\" + \"=\"*80)\n    outlier_df = pd.DataFrame(outlier_summary)\n    print(\"\\nFeatures with highest outlier rates (3σ method):\")\n    display(outlier_df.nlargest(5, '3std_pct')[['feature', 'n', '3std_outliers', '3std_pct']])\nelse:\n    print(\"⚠️  Data not available.\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Summary and Key Findings\n\nThis notebook provides comprehensive documentation of the MIMIC-IV data structure for biomarker discovery.\n\n### Data Structure Summary\n\n**7 Core Tables:**\n1. `patients.parquet` - Patient demographics (~300K patients)\n2. `admissions.parquet` - Hospital admissions (~500K admissions)\n3. `icustays.parquet` - ICU stays (~70K stays)\n4. `diagnoses_icd.parquet` - Diagnosis codes (~5M records)\n5. `d_icd_diagnoses.parquet` - ICD code lookup (~100K codes)\n6. `labevents.parquet` - Lab test results (~100M+ events) **← CBC data is here**\n7. `d_labitems.parquet` - Lab test catalog (~1.5K tests)\n\n### Key Questions Answered\n\n#### ✅ Q1: Where are CBC test results?\n**Answer:** In `labevents.parquet`\n- CBC components (WBC, RBC, Hemoglobin, Platelets, etc.) each have specific `itemid` values\n- `configs/cbc_features.yaml` maps feature names → itemids\n- Join `labevents` with `d_labitems` on `itemid` to get test names\n\n#### ✅ Q2: Are labevents.parquet or chartevents.parquet files available?\n**Answer:** Yes, `labevents.parquet` exists\n- Contains all laboratory test results including CBC\n- `chartevents.parquet` is NOT included (contains vital signs, not needed for CBC analysis)\n\n#### ✅ Q3: How are lab tests linked to admissions?\n**Answer:** Via `hadm_id` (hospital admission ID)\n- Each lab result has a `hadm_id` linking to `admissions.hadm_id`\n- This enables temporal analysis relative to admission time\n- Can filter labs to specific time windows (e.g., first 24 hours)\n\n### Table Relationships\n\n```\nPatients → Admissions → Diagnoses\n                     → ICU Stays\n                     → Lab Events → Lab Item Descriptions\n                                 → CBC Features\n```\n\n**Primary Keys:**\n- `subject_id` - Patient identifier (across all tables)\n- `hadm_id` - Hospital admission ID (links admissions, diagnoses, labs, ICU)\n- `itemid` - Lab test identifier (links lab results to test definitions)\n\n### Sample Query Patterns Documented\n\nThe notebook includes 6 production-ready query patterns:\n1. Get all CBC results for a patient\n2. Link admissions to diagnoses with descriptions\n3. Find patients with specific disease (by ICD code)\n4. Get CBC values within time window of admission\n5. Build patient-level feature matrix for ML\n6. Create comprehensive joined dataset\n\n### Next Steps for Pipeline Development\n\n1. **Data Acquisition**\n   - Run `scripts/download_mimic_from_bigquery.py` to download MIMIC-IV data\n   - Or create sample/synthetic data for testing\n\n2. **Data Preprocessing** (Issue #5)\n   - Implement preprocessing pipeline in `src/data/preprocessor.py`\n   - Handle missing values and outliers\n   - Standardize units across measurements\n\n3. **Feature Engineering** (Issue #6)\n   - Aggregate CBC values per patient/admission\n   - Create temporal features (trends, changes over time)\n   - Generate biomarker labels using threshold generators\n\n4. **Model Development**\n   - Build baseline classifiers for disease prediction\n   - Evaluate biomarker performance\n   - Compare literature-based vs data-driven thresholds\n\n### Configuration Files Available\n\n- `configs/cbc_features.yaml` - CBC feature definitions with reference ranges\n- `configs/diseases.yaml` - Target diseases with ICD-9/ICD-10 codes\n\n### Notes\n\n- This documentation is based on the MIMIC-IV 3.1 schema\n- Actual data must be downloaded separately (requires PhysioNet credentialed access)\n- The notebook is designed to work with or without data present\n- All analysis cells include conditional checks for data availability"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in CBC labs:\")\n",
    "print(cbc_labs.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for outliers\n",
    "print(\"\\nPotential outliers (beyond 3 std):\")\n",
    "for feature in cbc_labs['feature_name'].unique():\n",
    "    data = cbc_labs[cbc_labs['feature_name'] == feature]['valuenum']\n",
    "    mean, std = data.mean(), data.std()\n",
    "    outliers = ((data < mean - 3*std) | (data > mean + 3*std)).sum()\n",
    "    pct = 100 * outliers / len(data)\n",
    "    print(f\"  {feature}: {outliers:,} ({pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Implement data preprocessing pipeline\n",
    "2. Create patient-level feature aggregation\n",
    "3. Generate biomarker labels using threshold generators\n",
    "4. Build baseline prediction models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}