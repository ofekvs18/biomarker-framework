{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 - Exploratory Data Analysis\n",
    "\n",
    "This notebook performs initial exploration of MIMIC-IV data for biomarker discovery.\n",
    "\n",
    "## Objectives\n",
    "1. Load and inspect MIMIC-IV tables\n",
    "2. Explore CBC lab values distribution\n",
    "3. Analyze disease prevalence\n",
    "4. Identify data quality issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import yaml\n",
    "from pathlib import Path\n",
    "\n",
    "# Configure plotting\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data directory: ..\\data\\raw\n",
      "Data directory exists: True\n",
      "\n",
      "Available parquet files (7):\n",
      "  - admissions.parquet             (    15.7 MB)\n",
      "  - diagnoses_icd.parquet          (    21.5 MB)\n",
      "  - d_icd_diagnoses.parquet        (     1.9 MB)\n",
      "  - d_labitems.parquet             (     0.0 MB)\n",
      "  - icustays.parquet               (     4.3 MB)\n",
      "  - labevents.parquet              (    16.7 MB)\n",
      "  - patients.parquet               (     2.5 MB)\n",
      "\n",
      "Data available for analysis: True\n"
     ]
    }
   ],
   "source": [
    "# Set paths\n",
    "DATA_DIR = Path('../data/raw')\n",
    "CONFIG_DIR = Path('../configs')\n",
    "\n",
    "print(f\"Data directory: {DATA_DIR}\")\n",
    "print(f\"Data directory exists: {DATA_DIR.exists()}\")\n",
    "\n",
    "# List available data files\n",
    "if DATA_DIR.exists():\n",
    "    parquet_files = list(DATA_DIR.glob(\"*.parquet\"))\n",
    "    if parquet_files:\n",
    "        print(f\"\\nAvailable parquet files ({len(parquet_files)}):\")\n",
    "        for f in parquet_files:\n",
    "            size_mb = f.stat().st_size / (1024 ** 2)\n",
    "            print(f\"  - {f.name:30s} ({size_mb:>8.1f} MB)\")\n",
    "    else:\n",
    "        print(\"\\n⚠️  No parquet files found!\")\n",
    "        print(\"\\nTo download MIMIC-IV data, run:\")\n",
    "        print(\"  python scripts/download_mimic_from_bigquery.py --output-dir ../mimic_data\")\n",
    "        print(\"\\nExpected files:\")\n",
    "        expected_files = [\n",
    "            'patients.parquet',\n",
    "            'admissions.parquet', \n",
    "            'icustays.parquet',\n",
    "            'diagnoses_icd.parquet',\n",
    "            'd_icd_diagnoses.parquet',\n",
    "            'labevents.parquet',\n",
    "            'd_labitems.parquet'\n",
    "        ]\n",
    "        for fname in expected_files:\n",
    "            print(f\"  - {fname}\")\n",
    "else:\n",
    "    print(f\"\\n⚠️  Data directory does not exist: {DATA_DIR}\")\n",
    "\n",
    "# Flag to check if we can proceed with data loading\n",
    "DATA_AVAILABLE = DATA_DIR.exists() and len(list(DATA_DIR.glob(\"*.parquet\"))) > 0\n",
    "print(f\"\\nData available for analysis: {DATA_AVAILABLE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MIMIC-IV Data Structure Overview\n",
    "\n",
    "### Available Tables\n",
    "\n",
    "This analysis is based on the MIMIC-IV dataset structure. The following tables are expected in `data/raw/`:\n",
    "\n",
    "1. **patients.parquet** - Patient demographics\n",
    "2. **admissions.parquet** - Hospital admission records  \n",
    "3. **icustays.parquet** - ICU stay records\n",
    "4. **diagnoses_icd.parquet** - ICD diagnosis codes per admission\n",
    "5. **d_icd_diagnoses.parquet** - ICD code descriptions (lookup table)\n",
    "6. **labevents.parquet** - Laboratory test results (including CBC)\n",
    "7. **d_labitems.parquet** - Lab test catalog (lookup table)\n",
    "\n",
    "### Table Schemas\n",
    "\n",
    "#### 1. patients.parquet\n",
    "Primary patient demographics table.\n",
    "\n",
    "| Column | Type | Description |\n",
    "|--------|------|-------------|\n",
    "| subject_id | int | **PRIMARY KEY** - Unique patient identifier |\n",
    "| gender | str | Patient gender (M/F) |\n",
    "| anchor_age | int | Age at anchor_year |\n",
    "| anchor_year | int | Shifted year for de-identification |\n",
    "| anchor_year_group | str | Year range group |\n",
    "| dod | datetime | Date of death (if applicable) |\n",
    "\n",
    "**Rows:** ~300,000 unique patients\n",
    "\n",
    "---\n",
    "\n",
    "#### 2. admissions.parquet  \n",
    "Hospital admission records with demographics and outcome.\n",
    "\n",
    "| Column | Type | Description |\n",
    "|--------|------|-------------|\n",
    "| subject_id | int | **FOREIGN KEY** → patients.subject_id |\n",
    "| hadm_id | int | **PRIMARY KEY** - Hospital admission ID |\n",
    "| admittime | datetime | Admission timestamp |\n",
    "| dischtime | datetime | Discharge timestamp |\n",
    "| deathtime | datetime | Death time (if died during admission) |\n",
    "| admission_type | str | Type (e.g., EMERGENCY, ELECTIVE) |\n",
    "| admission_location | str | Where admitted from |\n",
    "| discharge_location | str | Where discharged to |\n",
    "| insurance | str | Insurance type |\n",
    "| language | str | Primary language |\n",
    "| marital_status | str | Marital status |\n",
    "| race | str | Race/ethnicity |\n",
    "| hospital_expire_flag | int | 1 if died in hospital, 0 otherwise |\n",
    "\n",
    "**Rows:** ~500,000 admissions\n",
    "\n",
    "---\n",
    "\n",
    "#### 3. icustays.parquet\n",
    "ICU stay records (subset of admissions that included ICU care).\n",
    "\n",
    "| Column | Type | Description |\n",
    "|--------|------|-------------|\n",
    "| subject_id | int | **FOREIGN KEY** → patients.subject_id |\n",
    "| hadm_id | int | **FOREIGN KEY** → admissions.hadm_id |\n",
    "| stay_id | int | **PRIMARY KEY** - ICU stay identifier |\n",
    "| first_careunit | str | First ICU care unit |\n",
    "| last_careunit | str | Last ICU care unit |\n",
    "| intime | datetime | ICU admission time |\n",
    "| outtime | datetime | ICU discharge time |\n",
    "| los | float | Length of stay (days) |\n",
    "\n",
    "**Rows:** ~70,000 ICU stays\n",
    "\n",
    "---\n",
    "\n",
    "#### 4. diagnoses_icd.parquet\n",
    "ICD diagnosis codes for each hospital admission.\n",
    "\n",
    "| Column | Type | Description |\n",
    "|--------|------|-------------|\n",
    "| subject_id | int | **FOREIGN KEY** → patients.subject_id |\n",
    "| hadm_id | int | **FOREIGN KEY** → admissions.hadm_id |\n",
    "| seq_num | int | Diagnosis sequence number (priority) |\n",
    "| icd_code | str | ICD diagnosis code |\n",
    "| icd_version | int | 9 (ICD-9) or 10 (ICD-10) |\n",
    "\n",
    "**Rows:** ~5,000,000 diagnosis records  \n",
    "**Note:** Each admission can have multiple diagnoses (seq_num orders by priority)\n",
    "\n",
    "---\n",
    "\n",
    "#### 5. d_icd_diagnoses.parquet\n",
    "ICD code descriptions (lookup/reference table).\n",
    "\n",
    "| Column | Type | Description |\n",
    "|--------|------|-------------|\n",
    "| icd_code | str | **PRIMARY KEY** - ICD code |\n",
    "| icd_version | int | 9 or 10 |\n",
    "| long_title | str | Full description of diagnosis |\n",
    "\n",
    "**Rows:** ~100,000 unique codes  \n",
    "**Purpose:** Joins with diagnoses_icd to get human-readable diagnosis names\n",
    "\n",
    "---\n",
    "\n",
    "#### 6. labevents.parquet ⚠️ LARGE TABLE\n",
    "Laboratory test results including all blood tests (CBC, chemistry, etc.).\n",
    "\n",
    "| Column | Type | Description |\n",
    "|--------|------|-------------|\n",
    "| labevent_id | int | **PRIMARY KEY** - Unique lab event ID |\n",
    "| subject_id | int | **FOREIGN KEY** → patients.subject_id |\n",
    "| hadm_id | int | **FOREIGN KEY** → admissions.hadm_id |\n",
    "| specimen_id | int | Specimen identifier |\n",
    "| itemid | int | **FOREIGN KEY** → d_labitems.itemid |\n",
    "| charttime | datetime | When lab was charted |\n",
    "| storetime | datetime | When lab was stored |\n",
    "| value | str | Lab result as string |\n",
    "| valuenum | float | Lab result as numeric value |\n",
    "| valueuom | str | Unit of measurement (e.g., 'g/dL', 'K/uL') |\n",
    "| ref_range_lower | float | Reference range lower bound |\n",
    "| ref_range_upper | float | Reference range upper bound |\n",
    "| flag | str | Abnormal flag indicator |\n",
    "| priority | str | Test priority (ROUTINE, STAT, etc.) |\n",
    "| comments | str | Additional comments |\n",
    "\n",
    "**Rows:** 100,000,000+ lab events (very large!)  \n",
    "**Note:** Filtered to only numeric values (valuenum IS NOT NULL) during download\n",
    "\n",
    "---\n",
    "\n",
    "#### 7. d_labitems.parquet\n",
    "Lab test catalog/definitions (lookup table).\n",
    "\n",
    "| Column | Type | Description |\n",
    "|--------|------|-------------|\n",
    "| itemid | int | **PRIMARY KEY** - Lab item identifier |\n",
    "| label | str | Lab test name (e.g., \"Hemoglobin\", \"Glucose\") |\n",
    "| fluid | str | Specimen fluid (e.g., \"Blood\", \"Urine\") |\n",
    "| category | str | Test category (e.g., \"Hematology\", \"Chemistry\") |\n",
    "\n",
    "**Rows:** ~1,500 unique lab tests  \n",
    "**Purpose:** Joins with labevents to get test names and categories\n",
    "\n",
    "---\n",
    "\n",
    "### Table Relationships\n",
    "\n",
    "```\n",
    "patients (subject_id)\n",
    "    │\n",
    "    ├──► admissions (subject_id, hadm_id)\n",
    "    │        │\n",
    "    │        ├──► icustays (hadm_id, stay_id)\n",
    "    │        │\n",
    "    │        ├──► diagnoses_icd (hadm_id, icd_code)\n",
    "    │        │        │\n",
    "    │        │        └──► d_icd_diagnoses (icd_code) [lookup]\n",
    "    │        │\n",
    "    │        └──► labevents (hadm_id, itemid)\n",
    "    │                 │\n",
    "    │                 └──► d_labitems (itemid) [lookup]\n",
    "    │\n",
    "    └──► labevents (subject_id)\n",
    "```\n",
    "\n",
    "### Key Relationships Summary\n",
    "\n",
    "| Join | Primary Table | Foreign Table | Join Columns | Purpose |\n",
    "|------|--------------|---------------|--------------|---------|\n",
    "| 1 | patients | admissions | subject_id | Get patient demographics for admission |\n",
    "| 2 | admissions | icustays | hadm_id | Find ICU stays for admission |\n",
    "| 3 | admissions | diagnoses_icd | hadm_id | Get diagnoses for admission |\n",
    "| 4 | diagnoses_icd | d_icd_diagnoses | icd_code, icd_version | Get diagnosis descriptions |\n",
    "| 5 | admissions | labevents | hadm_id | Get lab results for admission |\n",
    "| 6 | labevents | d_labitems | itemid | Get lab test name/category |\n",
    "| 7 | patients | labevents | subject_id | Get all labs for a patient |\n",
    "\n",
    "---\n",
    "\n",
    "### Answers to Key Questions\n",
    "\n",
    "#### Q1: Where are the CBC test results?\n",
    "**Answer:** CBC (Complete Blood Count) test results are in `labevents.parquet`.  \n",
    "\n",
    "- Each CBC component (WBC, RBC, Hemoglobin, Hematocrit, Platelets, etc.) has specific `itemid` values\n",
    "- The `configs/cbc_features.yaml` file maps CBC feature names to their corresponding itemids\n",
    "- Join `labevents` with `d_labitems` on `itemid` to get the human-readable test name\n",
    "\n",
    "#### Q2: Are there labevents.parquet or chartevents.parquet files?\n",
    "**Answer:** Yes, `labevents.parquet` exists and contains all laboratory test results.  \n",
    "\n",
    "- `chartevents.parquet` is NOT included in this pipeline (it contains vital signs, not lab tests)\n",
    "- All blood tests including CBC are in `labevents.parquet`\n",
    "\n",
    "#### Q3: How are lab tests linked to admissions?\n",
    "**Answer:** Via the `hadm_id` (hospital admission ID) column.\n",
    "\n",
    "- Each row in `labevents` has a `hadm_id` that links to `admissions.hadm_id`\n",
    "- This allows you to:\n",
    "  - Find all labs for a specific admission\n",
    "  - Link lab results to patient demographics, diagnoses, and outcomes\n",
    "  - Filter labs to specific time windows relative to admission\n",
    "\n",
    "**Example join:**\n",
    "```python\n",
    "# Get all CBC results for a specific admission\n",
    "admission_labs = labevents[labevents['hadm_id'] == specific_hadm_id]\n",
    "\n",
    "# Or join to get admission details with labs\n",
    "labs_with_admission = labevents.merge(\n",
    "    admissions[['hadm_id', 'subject_id', 'admittime', 'dischtime']], \n",
    "    on='hadm_id', \n",
    "    how='left'\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Data Extraction Queries\n",
    "\n",
    "Below are common query patterns for extracting biomarker data from MIMIC-IV tables.\n",
    "\n",
    "### Query 1: Get All CBC Results for a Patient\n",
    "\n",
    "```python\n",
    "# Get all CBC lab results for a specific patient\n",
    "def get_patient_cbc_labs(subject_id, labevents, d_labitems, cbc_itemids):\n",
    "    \"\"\"\n",
    "    Extract all CBC measurements for a patient\n",
    "    \n",
    "    Args:\n",
    "        subject_id: Patient identifier\n",
    "        labevents: Lab events DataFrame\n",
    "        d_labitems: Lab items lookup DataFrame\n",
    "        cbc_itemids: List of CBC test item IDs\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with CBC results\n",
    "    \"\"\"\n",
    "    # Filter to CBC tests for this patient\n",
    "    patient_cbc = labevents[\n",
    "        (labevents['subject_id'] == subject_id) & \n",
    "        (labevents['itemid'].isin(cbc_itemids))\n",
    "    ].copy()\n",
    "    \n",
    "    # Join with lab names\n",
    "    patient_cbc = patient_cbc.merge(\n",
    "        d_labitems[['itemid', 'label']], \n",
    "        on='itemid', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    return patient_cbc[['charttime', 'label', 'valuenum', 'valueuom', 'ref_range_lower', 'ref_range_upper']]\n",
    "```\n",
    "\n",
    "### Query 2: Link Admissions to Diagnoses\n",
    "\n",
    "```python\n",
    "# Get all diagnoses for admissions with human-readable descriptions\n",
    "def get_admission_diagnoses(admissions, diagnoses_icd, d_icd_diagnoses):\n",
    "    \"\"\"\n",
    "    Get all diagnoses for hospital admissions with descriptions\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with admission ID, ICD code, and diagnosis description\n",
    "    \"\"\"\n",
    "    # Join diagnoses with descriptions\n",
    "    diagnoses_with_desc = diagnoses_icd.merge(\n",
    "        d_icd_diagnoses[['icd_code', 'icd_version', 'long_title']], \n",
    "        on=['icd_code', 'icd_version'], \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Join with admissions to get admission details\n",
    "    admission_diagnoses = diagnoses_with_desc.merge(\n",
    "        admissions[['hadm_id', 'subject_id', 'admittime', 'dischtime']], \n",
    "        on='hadm_id', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    return admission_diagnoses.sort_values(['hadm_id', 'seq_num'])\n",
    "```\n",
    "\n",
    "### Query 3: Find Patients with Specific Disease\n",
    "\n",
    "```python\n",
    "# Find all patients diagnosed with sepsis (ICD-10: A41.x or ICD-9: 038.x)\n",
    "def find_patients_with_disease(icd_prefixes, diagnoses_icd):\n",
    "    \"\"\"\n",
    "    Find patients diagnosed with specific disease codes\n",
    "    \n",
    "    Args:\n",
    "        icd_prefixes: List of ICD code prefixes (e.g., ['A41', '038'])\n",
    "        diagnoses_icd: Diagnoses DataFrame\n",
    "    \n",
    "    Returns:\n",
    "        List of unique subject_ids\n",
    "    \"\"\"\n",
    "    # Create mask for any ICD code matching the prefixes\n",
    "    mask = diagnoses_icd['icd_code'].str.startswith(tuple(icd_prefixes))\n",
    "    \n",
    "    # Get unique patients\n",
    "    patient_ids = diagnoses_icd[mask]['subject_id'].unique()\n",
    "    \n",
    "    return patient_ids\n",
    "\n",
    "# Example: Find sepsis patients\n",
    "sepsis_patients = find_patients_with_disease(['A41', '038'], diagnoses_icd)\n",
    "print(f\"Found {len(sepsis_patients)} patients with sepsis\")\n",
    "```\n",
    "\n",
    "### Query 4: CBC Values at Admission Time\n",
    "\n",
    "```python\n",
    "# Get CBC values within first 24 hours of admission\n",
    "def get_admission_cbc(hadm_id, admissions, labevents, cbc_itemids, hours_window=24):\n",
    "    \"\"\"\n",
    "    Get CBC values near admission time\n",
    "    \n",
    "    Args:\n",
    "        hadm_id: Hospital admission ID\n",
    "        admissions: Admissions DataFrame\n",
    "        labevents: Lab events DataFrame\n",
    "        cbc_itemids: List of CBC test item IDs\n",
    "        hours_window: Time window after admission (default: 24 hours)\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with CBC results within time window\n",
    "    \"\"\"\n",
    "    # Get admission time\n",
    "    admission = admissions[admissions['hadm_id'] == hadm_id].iloc[0]\n",
    "    admit_time = admission['admittime']\n",
    "    \n",
    "    # Get labs for this admission\n",
    "    admission_labs = labevents[\n",
    "        (labevents['hadm_id'] == hadm_id) &\n",
    "        (labevents['itemid'].isin(cbc_itemids))\n",
    "    ].copy()\n",
    "    \n",
    "    # Filter to time window\n",
    "    admission_labs['hours_since_admit'] = (\n",
    "        (admission_labs['charttime'] - admit_time).dt.total_seconds() / 3600\n",
    "    )\n",
    "    \n",
    "    early_labs = admission_labs[\n",
    "        (admission_labs['hours_since_admit'] >= 0) &\n",
    "        (admission_labs['hours_since_admit'] <= hours_window)\n",
    "    ]\n",
    "    \n",
    "    return early_labs\n",
    "```\n",
    "\n",
    "### Query 5: Build Patient-Level Feature Matrix\n",
    "\n",
    "```python\n",
    "# Aggregate CBC values per patient for predictive modeling\n",
    "def build_patient_features(subject_ids, labevents, admissions, diagnoses_icd, \n",
    "                          cbc_itemids, target_icd_codes):\n",
    "    \"\"\"\n",
    "    Build patient-level feature matrix with:\n",
    "    - Aggregated CBC values (mean, std, min, max)\n",
    "    - Demographics\n",
    "    - Target disease label\n",
    "    \n",
    "    Args:\n",
    "        subject_ids: List of patient IDs\n",
    "        labevents: Lab events DataFrame\n",
    "        admissions: Admissions DataFrame\n",
    "        diagnoses_icd: Diagnoses DataFrame\n",
    "        cbc_itemids: List of CBC test item IDs\n",
    "        target_icd_codes: List of ICD codes for target disease\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with one row per patient\n",
    "    \"\"\"\n",
    "    patient_features = []\n",
    "    \n",
    "    for subject_id in subject_ids:\n",
    "        # Get CBC labs\n",
    "        patient_labs = labevents[\n",
    "            (labevents['subject_id'] == subject_id) &\n",
    "            (labevents['itemid'].isin(cbc_itemids))\n",
    "        ]\n",
    "        \n",
    "        # Aggregate by itemid\n",
    "        cbc_stats = patient_labs.groupby('itemid')['valuenum'].agg([\n",
    "            'mean', 'std', 'min', 'max', 'count'\n",
    "        ]).add_prefix('cbc_')\n",
    "        \n",
    "        # Get target label\n",
    "        patient_diagnoses = diagnoses_icd[diagnoses_icd['subject_id'] == subject_id]\n",
    "        has_disease = patient_diagnoses['icd_code'].str.startswith(\n",
    "            tuple(target_icd_codes)\n",
    "        ).any()\n",
    "        \n",
    "        # Combine features\n",
    "        features = {\n",
    "            'subject_id': subject_id,\n",
    "            'has_disease': int(has_disease),\n",
    "            **cbc_stats.to_dict('records')[0] if len(cbc_stats) > 0 else {}\n",
    "        }\n",
    "        \n",
    "        patient_features.append(features)\n",
    "    \n",
    "    return pd.DataFrame(patient_features)\n",
    "```\n",
    "\n",
    "### Query 6: Join Everything Together\n",
    "\n",
    "```python\n",
    "# Create comprehensive patient-admission-labs dataset\n",
    "def create_full_dataset(patients, admissions, labevents, diagnoses_icd, \n",
    "                       d_labitems, d_icd_diagnoses):\n",
    "    \"\"\"\n",
    "    Create a complete dataset joining all tables\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with patient demographics, admission details, lab results, and diagnoses\n",
    "    \"\"\"\n",
    "    # Start with labs\n",
    "    data = labevents.copy()\n",
    "    \n",
    "    # Add lab test names\n",
    "    data = data.merge(\n",
    "        d_labitems[['itemid', 'label', 'category']], \n",
    "        on='itemid', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Add admission details\n",
    "    data = data.merge(\n",
    "        admissions[['hadm_id', 'subject_id', 'admittime', 'dischtime', \n",
    "                   'admission_type', 'hospital_expire_flag']], \n",
    "        on=['hadm_id', 'subject_id'], \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Add patient demographics\n",
    "    data = data.merge(\n",
    "        patients[['subject_id', 'gender', 'anchor_age']], \n",
    "        on='subject_id', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Add primary diagnosis (seq_num = 1)\n",
    "    primary_dx = diagnoses_icd[diagnoses_icd['seq_num'] == 1].copy()\n",
    "    primary_dx = primary_dx.merge(\n",
    "        d_icd_diagnoses[['icd_code', 'icd_version', 'long_title']], \n",
    "        on=['icd_code', 'icd_version'], \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    data = data.merge(\n",
    "        primary_dx[['hadm_id', 'icd_code', 'long_title']], \n",
    "        on='hadm_id', \n",
    "        how='left',\n",
    "        suffixes=('', '_primary_dx')\n",
    "    )\n",
    "    \n",
    "    return data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Configuration Files"
   ]
  },
  {
   "cell_type": "code",
   "source": "# Load configuration files\ncbc_config_path = CONFIG_DIR / 'cbc_features.yaml'\ndiseases_config_path = CONFIG_DIR / 'diseases.yaml'\n\nif cbc_config_path.exists():\n    with open(cbc_config_path, 'r') as f:\n        cbc_config = yaml.safe_load(f)\n    print(f\"Loaded CBC config with {len(cbc_config.get('cbc_features', {}))} features\")\nelse:\n    print(f\"⚠️  CBC config not found at {cbc_config_path}\")\n    cbc_config = {'cbc_features': {}}\n\nif diseases_config_path.exists():\n    with open(diseases_config_path, 'r') as f:\n        diseases_config = yaml.safe_load(f)\n    print(f\"Loaded diseases config with {len(diseases_config.get('diseases', {}))} diseases\")\nelse:\n    print(f\"⚠️  Diseases config not found at {diseases_config_path}\")\n    diseases_config = {'diseases': {}}",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load patients\n",
    "if DATA_AVAILABLE:\n",
    "    if (DATA_DIR / 'patients.parquet').exists():\n",
    "        patients = pd.read_parquet(DATA_DIR / 'patients.parquet')\n",
    "        print(f\"Patients: {len(patients):,} rows × {len(patients.columns)} columns\")\n",
    "        print(f\"\\nColumns: {list(patients.columns)}\")\n",
    "        print(f\"\\nData types:\")\n",
    "        print(patients.dtypes)\n",
    "        print(f\"\\nFirst few rows:\")\n",
    "        display(patients.head())\n",
    "        print(f\"\\nSummary statistics:\")\n",
    "        display(patients.describe())\n",
    "    else:\n",
    "        print(\"⚠️  patients.parquet not found\")\n",
    "else:\n",
    "    print(\"⚠️  Data not available. See instructions above to download MIMIC-IV data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Admissions: 546,028 rows × 13 columns\n",
      "\n",
      "Columns: ['subject_id', 'hadm_id', 'admittime', 'dischtime', 'deathtime', 'admission_type', 'admission_location', 'discharge_location', 'insurance', 'language', 'marital_status', 'race', 'hospital_expire_flag']\n",
      "\n",
      "Data types:\n",
      "subject_id                       Int64\n",
      "hadm_id                          Int64\n",
      "admittime               datetime64[us]\n",
      "dischtime               datetime64[us]\n",
      "deathtime               datetime64[us]\n",
      "admission_type                  object\n",
      "admission_location              object\n",
      "discharge_location              object\n",
      "insurance                       object\n",
      "language                        object\n",
      "marital_status                  object\n",
      "race                            object\n",
      "hospital_expire_flag             Int64\n",
      "dtype: object\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>admittime</th>\n",
       "      <th>dischtime</th>\n",
       "      <th>deathtime</th>\n",
       "      <th>admission_type</th>\n",
       "      <th>admission_location</th>\n",
       "      <th>discharge_location</th>\n",
       "      <th>insurance</th>\n",
       "      <th>language</th>\n",
       "      <th>marital_status</th>\n",
       "      <th>race</th>\n",
       "      <th>hospital_expire_flag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10106244</td>\n",
       "      <td>26713233</td>\n",
       "      <td>2147-05-09 10:34:00</td>\n",
       "      <td>2147-05-12 13:43:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>DIRECT EMER.</td>\n",
       "      <td>PHYSICIAN REFERRAL</td>\n",
       "      <td>HOME</td>\n",
       "      <td>Private</td>\n",
       "      <td>English</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13700703</td>\n",
       "      <td>20448599</td>\n",
       "      <td>2172-09-25 01:01:00</td>\n",
       "      <td>2172-10-03 13:25:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>OBSERVATION ADMIT</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>HOME</td>\n",
       "      <td>Private</td>\n",
       "      <td>English</td>\n",
       "      <td>MARRIED</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15443666</td>\n",
       "      <td>27961368</td>\n",
       "      <td>2168-12-30 23:30:00</td>\n",
       "      <td>2169-01-05 16:02:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>OBSERVATION ADMIT</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>HOME HEALTH CARE</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>English</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16299919</td>\n",
       "      <td>26977065</td>\n",
       "      <td>2193-05-15 08:37:00</td>\n",
       "      <td>2193-05-17 16:03:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>OBSERVATION ADMIT</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>HOSPICE</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>English</td>\n",
       "      <td>WIDOWED</td>\n",
       "      <td>BLACK/AFRICAN AMERICAN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14149715</td>\n",
       "      <td>24191358</td>\n",
       "      <td>2181-10-25 19:37:00</td>\n",
       "      <td>2181-10-29 14:38:00</td>\n",
       "      <td>NaT</td>\n",
       "      <td>OBSERVATION ADMIT</td>\n",
       "      <td>EMERGENCY ROOM</td>\n",
       "      <td>SKILLED NURSING FACILITY</td>\n",
       "      <td>Medicare</td>\n",
       "      <td>English</td>\n",
       "      <td>SINGLE</td>\n",
       "      <td>WHITE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id           admittime           dischtime deathtime  \\\n",
       "0    10106244  26713233 2147-05-09 10:34:00 2147-05-12 13:43:00       NaT   \n",
       "1    13700703  20448599 2172-09-25 01:01:00 2172-10-03 13:25:00       NaT   \n",
       "2    15443666  27961368 2168-12-30 23:30:00 2169-01-05 16:02:00       NaT   \n",
       "3    16299919  26977065 2193-05-15 08:37:00 2193-05-17 16:03:00       NaT   \n",
       "4    14149715  24191358 2181-10-25 19:37:00 2181-10-29 14:38:00       NaT   \n",
       "\n",
       "      admission_type  admission_location        discharge_location insurance  \\\n",
       "0       DIRECT EMER.  PHYSICIAN REFERRAL                      HOME   Private   \n",
       "1  OBSERVATION ADMIT      EMERGENCY ROOM                      HOME   Private   \n",
       "2  OBSERVATION ADMIT      EMERGENCY ROOM          HOME HEALTH CARE  Medicare   \n",
       "3  OBSERVATION ADMIT      EMERGENCY ROOM                   HOSPICE  Medicare   \n",
       "4  OBSERVATION ADMIT      EMERGENCY ROOM  SKILLED NURSING FACILITY  Medicare   \n",
       "\n",
       "  language marital_status                    race  hospital_expire_flag  \n",
       "0  English         SINGLE                   WHITE                     0  \n",
       "1  English        MARRIED                   WHITE                     0  \n",
       "2  English         SINGLE  BLACK/AFRICAN AMERICAN                     0  \n",
       "3  English        WIDOWED  BLACK/AFRICAN AMERICAN                     0  \n",
       "4  English         SINGLE                   WHITE                     0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Admission types:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "admission_type\n",
       "EW EMER.                       177459\n",
       "EU OBSERVATION                 119456\n",
       "OBSERVATION ADMIT               84437\n",
       "URGENT                          54929\n",
       "SURGICAL SAME DAY ADMISSION     42898\n",
       "DIRECT OBSERVATION              24551\n",
       "DIRECT EMER.                    21973\n",
       "ELECTIVE                        13130\n",
       "AMBULATORY OBSERVATION           7195\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load admissions\n",
    "if DATA_AVAILABLE:\n",
    "    if (DATA_DIR / 'admissions.parquet').exists():\n",
    "        admissions = pd.read_parquet(DATA_DIR / 'admissions.parquet')\n",
    "        print(f\"Admissions: {len(admissions):,} rows × {len(admissions.columns)} columns\")\n",
    "        print(f\"\\nColumns: {list(admissions.columns)}\")\n",
    "        print(f\"\\nData types:\")\n",
    "        print(admissions.dtypes)\n",
    "        print(f\"\\nFirst few rows:\")\n",
    "        display(admissions.head())\n",
    "        print(f\"\\nAdmission types:\")\n",
    "        display(admissions['admission_type'].value_counts())\n",
    "    else:\n",
    "        print(\"⚠️  admissions.parquet not found\")\n",
    "else:\n",
    "    print(\"⚠️  Data not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load diagnoses\n",
    "if DATA_AVAILABLE:\n",
    "    if (DATA_DIR / 'diagnoses_icd.parquet').exists():\n",
    "        diagnoses = pd.read_parquet(DATA_DIR / 'diagnoses_icd.parquet')\n",
    "        print(f\"Diagnoses: {len(diagnoses):,} rows × {len(diagnoses.columns)} columns\")\n",
    "        print(f\"\\nColumns: {list(diagnoses.columns)}\")\n",
    "        print(f\"\\nData types:\")\n",
    "        print(diagnoses.dtypes)\n",
    "        print(f\"\\nICD version distribution:\")\n",
    "        display(diagnoses['icd_version'].value_counts())\n",
    "        print(f\"\\nFirst few rows:\")\n",
    "        display(diagnoses.head())\n",
    "    else:\n",
    "        print(\"⚠️  diagnoses_icd.parquet not found\")\n",
    "else:\n",
    "    print(\"⚠️  Data not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lab items: 1,650 rows × 4 columns\n",
      "\n",
      "Columns: ['itemid', 'label', 'fluid', 'category']\n",
      "\n",
      "Categories:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "category\n",
       "Chemistry     800\n",
       "Hematology    785\n",
       "Blood Gas      65\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First 10 rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>label</th>\n",
       "      <th>fluid</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>50801</td>\n",
       "      <td>Alveolar-arterial Gradient</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Blood Gas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50802</td>\n",
       "      <td>Base Excess</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Blood Gas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50803</td>\n",
       "      <td>Calculated Bicarbonate, Whole Blood</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Blood Gas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50804</td>\n",
       "      <td>Calculated Total CO2</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Blood Gas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50805</td>\n",
       "      <td>Carboxyhemoglobin</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Blood Gas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>50806</td>\n",
       "      <td>Chloride, Whole Blood</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Blood Gas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>50808</td>\n",
       "      <td>Free Calcium</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Blood Gas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>50809</td>\n",
       "      <td>Glucose</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Blood Gas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>50810</td>\n",
       "      <td>Hematocrit, Calculated</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Blood Gas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>50811</td>\n",
       "      <td>Hemoglobin</td>\n",
       "      <td>Blood</td>\n",
       "      <td>Blood Gas</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   itemid                                label  fluid   category\n",
       "0   50801           Alveolar-arterial Gradient  Blood  Blood Gas\n",
       "1   50802                          Base Excess  Blood  Blood Gas\n",
       "2   50803  Calculated Bicarbonate, Whole Blood  Blood  Blood Gas\n",
       "3   50804                 Calculated Total CO2  Blood  Blood Gas\n",
       "4   50805                    Carboxyhemoglobin  Blood  Blood Gas\n",
       "5   50806                Chloride, Whole Blood  Blood  Blood Gas\n",
       "6   50808                         Free Calcium  Blood  Blood Gas\n",
       "7   50809                              Glucose  Blood  Blood Gas\n",
       "8   50810               Hematocrit, Calculated  Blood  Blood Gas\n",
       "9   50811                           Hemoglobin  Blood  Blood Gas"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load lab items dictionary\n",
    "if DATA_AVAILABLE:\n",
    "    if (DATA_DIR / 'd_labitems.parquet').exists():\n",
    "        d_labitems = pd.read_parquet(DATA_DIR / 'd_labitems.parquet')\n",
    "        print(f\"Lab items: {len(d_labitems):,} rows × {len(d_labitems.columns)} columns\")\n",
    "        print(f\"\\nColumns: {list(d_labitems.columns)}\")\n",
    "        print(f\"\\nCategories:\")\n",
    "        display(d_labitems['category'].value_counts())\n",
    "        print(f\"\\nFirst 10 rows:\")\n",
    "        display(d_labitems.head(10))\n",
    "    else:\n",
    "        print(\"⚠️  d_labitems.parquet not found\")\n",
    "else:\n",
    "    print(\"⚠️  Data not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading labevents (this may take a moment for large files)...\n",
      "Lab events: 1,000,000 rows × 15 columns\n",
      "\n",
      "Columns: ['labevent_id', 'subject_id', 'hadm_id', 'specimen_id', 'itemid', 'charttime', 'storetime', 'value', 'valuenum', 'valueuom', 'ref_range_lower', 'ref_range_upper', 'flag', 'priority', 'comments']\n",
      "\n",
      "Data types:\n",
      "labevent_id                 Int64\n",
      "subject_id                  Int64\n",
      "hadm_id                     Int64\n",
      "specimen_id                 Int64\n",
      "itemid                      Int64\n",
      "charttime          datetime64[us]\n",
      "storetime          datetime64[us]\n",
      "value                      object\n",
      "valuenum                  float64\n",
      "valueuom                   object\n",
      "ref_range_lower           float64\n",
      "ref_range_upper           float64\n",
      "flag                       object\n",
      "priority                   object\n",
      "comments                   object\n",
      "dtype: object\n",
      "\n",
      "Memory usage: 0.28 GB\n",
      "\n",
      "First few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>labevent_id</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>specimen_id</th>\n",
       "      <th>itemid</th>\n",
       "      <th>charttime</th>\n",
       "      <th>storetime</th>\n",
       "      <th>value</th>\n",
       "      <th>valuenum</th>\n",
       "      <th>valueuom</th>\n",
       "      <th>ref_range_lower</th>\n",
       "      <th>ref_range_upper</th>\n",
       "      <th>flag</th>\n",
       "      <th>priority</th>\n",
       "      <th>comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>10000032</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>91029538</td>\n",
       "      <td>51301</td>\n",
       "      <td>2180-03-23 11:51:00</td>\n",
       "      <td>2180-03-23 15:19:00</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>K/uL</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>ROUTINE</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25</td>\n",
       "      <td>10000032</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>83925500</td>\n",
       "      <td>50907</td>\n",
       "      <td>2180-03-23 11:51:00</td>\n",
       "      <td>2180-03-23 16:40:00</td>\n",
       "      <td>202</td>\n",
       "      <td>202.0</td>\n",
       "      <td>mg/dL</td>\n",
       "      <td>0.0</td>\n",
       "      <td>199.0</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>ROUTINE</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29</td>\n",
       "      <td>10000032</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>83925500</td>\n",
       "      <td>50924</td>\n",
       "      <td>2180-03-23 11:51:00</td>\n",
       "      <td>2180-03-23 16:40:00</td>\n",
       "      <td>90</td>\n",
       "      <td>90.0</td>\n",
       "      <td>ng/mL</td>\n",
       "      <td>13.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>None</td>\n",
       "      <td>ROUTINE</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>10000032</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>94031677</td>\n",
       "      <td>51514</td>\n",
       "      <td>2180-03-23 11:51:00</td>\n",
       "      <td>2180-03-23 15:38:00</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>mg/dL</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>ROUTINE</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26</td>\n",
       "      <td>10000032</td>\n",
       "      <td>&lt;NA&gt;</td>\n",
       "      <td>83925500</td>\n",
       "      <td>50912</td>\n",
       "      <td>2180-03-23 11:51:00</td>\n",
       "      <td>2180-03-23 16:40:00</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.4</td>\n",
       "      <td>mg/dL</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.1</td>\n",
       "      <td>None</td>\n",
       "      <td>ROUTINE</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   labevent_id  subject_id  hadm_id  specimen_id  itemid           charttime  \\\n",
       "0           63    10000032     <NA>     91029538   51301 2180-03-23 11:51:00   \n",
       "1           25    10000032     <NA>     83925500   50907 2180-03-23 11:51:00   \n",
       "2           29    10000032     <NA>     83925500   50924 2180-03-23 11:51:00   \n",
       "3           75    10000032     <NA>     94031677   51514 2180-03-23 11:51:00   \n",
       "4           26    10000032     <NA>     83925500   50912 2180-03-23 11:51:00   \n",
       "\n",
       "            storetime value  valuenum valueuom  ref_range_lower  \\\n",
       "0 2180-03-23 15:19:00   3.0       3.0     K/uL              4.0   \n",
       "1 2180-03-23 16:40:00   202     202.0    mg/dL              0.0   \n",
       "2 2180-03-23 16:40:00    90      90.0    ng/mL             13.0   \n",
       "3 2180-03-23 15:38:00     2       2.0    mg/dL              0.2   \n",
       "4 2180-03-23 16:40:00   0.4       0.4    mg/dL              0.4   \n",
       "\n",
       "   ref_range_upper      flag priority comments  \n",
       "0             11.0  abnormal  ROUTINE     None  \n",
       "1            199.0  abnormal  ROUTINE     None  \n",
       "2            150.0      None  ROUTINE     None  \n",
       "3              1.0  abnormal  ROUTINE     None  \n",
       "4              1.1      None  ROUTINE     None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of numeric values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "count    1.000000e+06\n",
       "mean     7.432949e+01\n",
       "std      2.894812e+03\n",
       "min     -1.074000e+03\n",
       "25%      3.700000e+00\n",
       "50%      1.400000e+01\n",
       "75%      4.500000e+01\n",
       "max      1.130000e+06\n",
       "Name: valuenum, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load lab events (may take a moment - large file)\n",
    "if DATA_AVAILABLE:\n",
    "    if (DATA_DIR / 'labevents.parquet').exists():\n",
    "        print(\"Loading labevents (this may take a moment for large files)...\")\n",
    "        labevents = pd.read_parquet(DATA_DIR / 'labevents.parquet')\n",
    "        print(f\"Lab events: {len(labevents):,} rows × {len(labevents.columns)} columns\")\n",
    "        print(f\"\\nColumns: {list(labevents.columns)}\")\n",
    "        print(f\"\\nData types:\")\n",
    "        print(labevents.dtypes)\n",
    "        print(f\"\\nMemory usage: {labevents.memory_usage(deep=True).sum() / 1024**3:.2f} GB\")\n",
    "        print(f\"\\nFirst few rows:\")\n",
    "        display(labevents.head())\n",
    "        print(f\"\\nSummary of numeric values:\")\n",
    "        display(labevents['valuenum'].describe())\n",
    "    else:\n",
    "        print(\"⚠️  labevents.parquet not found\")\n",
    "else:\n",
    "    print(\"⚠️  Data not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diagnoses: 6,364,488 rows\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>hadm_id</th>\n",
       "      <th>seq_num</th>\n",
       "      <th>icd_code</th>\n",
       "      <th>icd_version</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>1</td>\n",
       "      <td>5723</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>2</td>\n",
       "      <td>78959</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>3</td>\n",
       "      <td>5715</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>4</td>\n",
       "      <td>07070</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000032</td>\n",
       "      <td>22595853</td>\n",
       "      <td>5</td>\n",
       "      <td>496</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id   hadm_id  seq_num icd_code  icd_version\n",
       "0    10000032  22595853        1     5723            9\n",
       "1    10000032  22595853        2    78959            9\n",
       "2    10000032  22595853        3     5715            9\n",
       "3    10000032  22595853        4    07070            9\n",
       "4    10000032  22595853        5      496            9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load diagnoses\n",
    "diagnoses = pd.read_parquet(DATA_DIR / 'diagnoses_icd.parquet')\n",
    "print(f\"Diagnoses: {len(diagnoses):,} rows\")\n",
    "diagnoses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cbc_config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m cbc_itemids = []\n\u001b[32m      4\u001b[39m itemid_to_name = {}\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m feature_name, feature_info \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcbc_config\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mcbc_features\u001b[39m\u001b[33m'\u001b[39m].items():\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m itemid \u001b[38;5;129;01min\u001b[39;00m feature_info[\u001b[33m'\u001b[39m\u001b[33mitemids\u001b[39m\u001b[33m'\u001b[39m]:\n\u001b[32m      8\u001b[39m         cbc_itemids.append(itemid)\n",
      "\u001b[31mNameError\u001b[39m: name 'cbc_config' is not defined"
     ]
    }
   ],
   "source": [
    "# Get CBC itemids from config\n",
    "if DATA_AVAILABLE:\n",
    "    cbc_itemids = []\n",
    "    itemid_to_name = {}\n",
    "\n",
    "    for feature_name, feature_info in cbc_config['cbc_features'].items():\n",
    "        for itemid in feature_info['itemids']:\n",
    "            cbc_itemids.append(itemid)\n",
    "            itemid_to_name[itemid] = feature_name\n",
    "\n",
    "    print(f\"Total CBC itemids: {len(cbc_itemids)}\")\n",
    "    print(f\"\\nCBC features mapped:\")\n",
    "    for feature_name, feature_info in cbc_config['cbc_features'].items():\n",
    "        itemids = feature_info['itemids']\n",
    "        print(f\"  {feature_name:20s} → itemids: {itemids}\")\n",
    "else:\n",
    "    print(\"⚠️  Data not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to CBC labs only\n",
    "if DATA_AVAILABLE and 'labevents' in dir():\n",
    "    cbc_labs = labevents[labevents['itemid'].isin(cbc_itemids)].copy()\n",
    "    cbc_labs['feature_name'] = cbc_labs['itemid'].map(itemid_to_name)\n",
    "\n",
    "    print(f\"Total lab events: {len(labevents):,}\")\n",
    "    print(f\"CBC lab events: {len(cbc_labs):,} ({100*len(cbc_labs)/len(labevents):.2f}%)\")\n",
    "    print(f\"\\nCBC features found:\")\n",
    "    print(cbc_labs['feature_name'].value_counts())\n",
    "    print(f\"\\nFirst few CBC lab results:\")\n",
    "    display(cbc_labs.head(10))\n",
    "else:\n",
    "    print(\"⚠️  Data not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary statistics per CBC feature\n",
    "if DATA_AVAILABLE and 'cbc_labs' in dir():\n",
    "    cbc_summary = cbc_labs.groupby('feature_name')['valuenum'].describe()\n",
    "    print(\"CBC Feature Summary Statistics:\")\n",
    "    display(cbc_summary)\n",
    "    \n",
    "    print(\"\\n\\nCBC value ranges vs reference ranges from config:\")\n",
    "    for feature_name in cbc_labs['feature_name'].unique():\n",
    "        if pd.notna(feature_name) and feature_name in cbc_config['cbc_features']:\n",
    "            feature_data = cbc_labs[cbc_labs['feature_name'] == feature_name]['valuenum']\n",
    "            ref_range = cbc_config['cbc_features'][feature_name].get('reference_range', {})\n",
    "            \n",
    "            print(f\"\\n{feature_name}:\")\n",
    "            print(f\"  Observed: {feature_data.min():.2f} - {feature_data.max():.2f}\")\n",
    "            print(f\"  Reference: {ref_range.get('low', 'N/A')} - {ref_range.get('high', 'N/A')}\")\n",
    "            print(f\"  Mean: {feature_data.mean():.2f}, Median: {feature_data.median():.2f}\")\n",
    "else:\n",
    "    print(\"⚠️  Data not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distributions\n",
    "if DATA_AVAILABLE and 'cbc_labs' in dir():\n",
    "    # Create output directory if needed\n",
    "    import os\n",
    "    os.makedirs('../experiments', exist_ok=True)\n",
    "    \n",
    "    unique_features = cbc_labs['feature_name'].dropna().unique()\n",
    "    n_features = len(unique_features)\n",
    "    \n",
    "    # Calculate grid size\n",
    "    n_cols = 4\n",
    "    n_rows = (n_features + n_cols - 1) // n_cols\n",
    "    \n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(16, n_rows * 3))\n",
    "    axes = axes.flatten() if n_rows > 1 else [axes]\n",
    "    \n",
    "    for idx, feature_name in enumerate(unique_features):\n",
    "        data = cbc_labs[cbc_labs['feature_name'] == feature_name]['valuenum'].dropna()\n",
    "        \n",
    "        # Get reference range from config\n",
    "        if feature_name in cbc_config['cbc_features']:\n",
    "            ref_range = cbc_config['cbc_features'][feature_name].get('reference_range', {})\n",
    "            low = ref_range.get('low')\n",
    "            high = ref_range.get('high')\n",
    "        else:\n",
    "            low, high = None, None\n",
    "        \n",
    "        ax = axes[idx]\n",
    "        \n",
    "        # Plot histogram\n",
    "        ax.hist(data, bins=50, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "        ax.set_title(f'{feature_name}\\n(n={len(data):,})', fontsize=10)\n",
    "        ax.set_xlabel('Value', fontsize=9)\n",
    "        ax.set_ylabel('Count', fontsize=9)\n",
    "        \n",
    "        # Add reference range lines\n",
    "        if low is not None:\n",
    "            ax.axvline(low, color='red', linestyle='--', linewidth=2, label=f'Low: {low}')\n",
    "        if high is not None:\n",
    "            ax.axvline(high, color='red', linestyle='--', linewidth=2, label=f'High: {high}')\n",
    "        \n",
    "        if low is not None or high is not None:\n",
    "            ax.legend(fontsize=7)\n",
    "        \n",
    "        # Format axis\n",
    "        ax.tick_params(labelsize=8)\n",
    "    \n",
    "    # Hide empty subplots\n",
    "    for idx in range(n_features, len(axes)):\n",
    "        axes[idx].set_visible(False)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../experiments/cbc_distributions.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"Saved plot to ../experiments/cbc_distributions.png\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"⚠️  Data not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to CBC labs only\n",
    "cbc_labs = labevents[labevents['itemid'].isin(cbc_itemids)].copy()\n",
    "cbc_labs['feature_name'] = cbc_labs['itemid'].map(itemid_to_name)\n",
    "\n",
    "print(f\"CBC lab events: {len(cbc_labs):,} rows\")\n",
    "cbc_labs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count patients per disease\n",
    "if DATA_AVAILABLE and 'diagnoses' in dir():\n",
    "    disease_counts = {}\n",
    "\n",
    "    for disease_name, disease_info in diseases_config['diseases'].items():\n",
    "        icd_codes = disease_info.get('icd9_codes', []) + disease_info.get('icd10_codes', [])\n",
    "        \n",
    "        # Match patients with these ICD codes\n",
    "        mask = diagnoses['icd_code'].str.startswith(tuple(icd_codes))\n",
    "        patient_count = diagnoses[mask]['subject_id'].nunique()\n",
    "        admission_count = diagnoses[mask]['hadm_id'].nunique()\n",
    "        \n",
    "        disease_counts[disease_name] = {\n",
    "            'patients': patient_count,\n",
    "            'admissions': admission_count,\n",
    "            'icd_codes': icd_codes\n",
    "        }\n",
    "\n",
    "    disease_df = pd.DataFrame({\n",
    "        'disease': disease_counts.keys(),\n",
    "        'patient_count': [v['patients'] for v in disease_counts.values()],\n",
    "        'admission_count': [v['admissions'] for v in disease_counts.values()]\n",
    "    }).sort_values('patient_count', ascending=False)\n",
    "\n",
    "    print(\"Disease Prevalence in Dataset:\")\n",
    "    display(disease_df)\n",
    "    \n",
    "    print(\"\\n\\nDetailed breakdown:\")\n",
    "    for disease_name, info in disease_counts.items():\n",
    "        print(f\"\\n{disease_name}:\")\n",
    "        print(f\"  Patients: {info['patients']:,}\")\n",
    "        print(f\"  Admissions: {info['admissions']:,}\")\n",
    "        print(f\"  ICD codes: {info['icd_codes']}\")\n",
    "else:\n",
    "    print(\"⚠️  Data not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot disease prevalence\n",
    "if DATA_AVAILABLE and 'disease_df' in dir():\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Plot patient counts\n",
    "    ax1.barh(disease_df['disease'], disease_df['patient_count'], color='steelblue')\n",
    "    ax1.set_xlabel('Number of Unique Patients', fontsize=12)\n",
    "    ax1.set_ylabel('Disease', fontsize=12)\n",
    "    ax1.set_title('Disease Prevalence by Patient Count', fontsize=14, fontweight='bold')\n",
    "    ax1.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, v in enumerate(disease_df['patient_count']):\n",
    "        ax1.text(v, i, f' {v:,}', va='center', fontsize=10)\n",
    "    \n",
    "    # Plot admission counts\n",
    "    ax2.barh(disease_df['disease'], disease_df['admission_count'], color='coral')\n",
    "    ax2.set_xlabel('Number of Admissions', fontsize=12)\n",
    "    ax2.set_ylabel('Disease', fontsize=12)\n",
    "    ax2.set_title('Disease Prevalence by Admission Count', fontsize=14, fontweight='bold')\n",
    "    ax2.grid(axis='x', alpha=0.3)\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, v in enumerate(disease_df['admission_count']):\n",
    "        ax2.text(v, i, f' {v:,}', va='center', fontsize=10)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('../experiments/disease_prevalence.png', dpi=150, bbox_inches='tight')\n",
    "    print(\"Saved plot to ../experiments/disease_prevalence.png\")\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"⚠️  Data not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Disease Prevalence Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "if DATA_AVAILABLE and 'cbc_labs' in dir():\n",
    "    print(\"Missing values in CBC labs:\")\n",
    "    missing = cbc_labs.isnull().sum()\n",
    "    missing_pct = 100 * missing / len(cbc_labs)\n",
    "    \n",
    "    missing_df = pd.DataFrame({\n",
    "        'column': missing.index,\n",
    "        'missing_count': missing.values,\n",
    "        'missing_pct': missing_pct.values\n",
    "    }).sort_values('missing_count', ascending=False)\n",
    "    \n",
    "    display(missing_df[missing_df['missing_count'] > 0])\n",
    "    \n",
    "    print(f\"\\n\\nTotal CBC lab rows: {len(cbc_labs):,}\")\n",
    "    print(f\"Rows with missing valuenum: {cbc_labs['valuenum'].isnull().sum():,}\")\n",
    "else:\n",
    "    print(\"⚠️  Data not available.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for outliers\n",
    "if DATA_AVAILABLE and 'cbc_labs' in dir():\n",
    "    print(\"Potential outliers (beyond 3 standard deviations):\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    outlier_summary = []\n",
    "    \n",
    "    for feature in sorted(cbc_labs['feature_name'].dropna().unique()):\n",
    "        data = cbc_labs[cbc_labs['feature_name'] == feature]['valuenum'].dropna()\n",
    "        \n",
    "        if len(data) > 0:\n",
    "            mean, std = data.mean(), data.std()\n",
    "            median = data.median()\n",
    "            \n",
    "            # Count outliers beyond 3 std\n",
    "            lower_bound = mean - 3*std\n",
    "            upper_bound = mean + 3*std\n",
    "            outliers = ((data < lower_bound) | (data > upper_bound)).sum()\n",
    "            pct = 100 * outliers / len(data)\n",
    "            \n",
    "            # Also check using IQR method\n",
    "            q1, q3 = data.quantile(0.25), data.quantile(0.75)\n",
    "            iqr = q3 - q1\n",
    "            iqr_lower = q1 - 1.5*iqr\n",
    "            iqr_upper = q3 + 1.5*iqr\n",
    "            iqr_outliers = ((data < iqr_lower) | (data > iqr_upper)).sum()\n",
    "            iqr_pct = 100 * iqr_outliers / len(data)\n",
    "            \n",
    "            outlier_summary.append({\n",
    "                'feature': feature,\n",
    "                'n': len(data),\n",
    "                'mean': mean,\n",
    "                'median': median,\n",
    "                'std': std,\n",
    "                '3std_outliers': outliers,\n",
    "                '3std_pct': pct,\n",
    "                'iqr_outliers': iqr_outliers,\n",
    "                'iqr_pct': iqr_pct\n",
    "            })\n",
    "            \n",
    "            print(f\"{feature:20s} | n={len(data):>8,} | 3σ outliers: {outliers:>7,} ({pct:>5.2f}%) | IQR outliers: {iqr_outliers:>7,} ({iqr_pct:>5.2f}%)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    outlier_df = pd.DataFrame(outlier_summary)\n",
    "    print(\"\\nFeatures with highest outlier rates (3σ method):\")\n",
    "    display(outlier_df.nlargest(5, '3std_pct')[['feature', 'n', '3std_outliers', '3std_pct']])\n",
    "else:\n",
    "    print(\"⚠️  Data not available.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary and Key Findings\n",
    "\n",
    "This notebook provides comprehensive documentation of the MIMIC-IV data structure for biomarker discovery.\n",
    "\n",
    "### Data Structure Summary\n",
    "\n",
    "**7 Core Tables:**\n",
    "1. `patients.parquet` - Patient demographics (~300K patients)\n",
    "2. `admissions.parquet` - Hospital admissions (~500K admissions)\n",
    "3. `icustays.parquet` - ICU stays (~70K stays)\n",
    "4. `diagnoses_icd.parquet` - Diagnosis codes (~5M records)\n",
    "5. `d_icd_diagnoses.parquet` - ICD code lookup (~100K codes)\n",
    "6. `labevents.parquet` - Lab test results (~100M+ events) **← CBC data is here**\n",
    "7. `d_labitems.parquet` - Lab test catalog (~1.5K tests)\n",
    "\n",
    "### Key Questions Answered\n",
    "\n",
    "#### ✅ Q1: Where are CBC test results?\n",
    "**Answer:** In `labevents.parquet`\n",
    "- CBC components (WBC, RBC, Hemoglobin, Platelets, etc.) each have specific `itemid` values\n",
    "- `configs/cbc_features.yaml` maps feature names → itemids\n",
    "- Join `labevents` with `d_labitems` on `itemid` to get test names\n",
    "\n",
    "#### ✅ Q2: Are labevents.parquet or chartevents.parquet files available?\n",
    "**Answer:** Yes, `labevents.parquet` exists\n",
    "- Contains all laboratory test results including CBC\n",
    "- `chartevents.parquet` is NOT included (contains vital signs, not needed for CBC analysis)\n",
    "\n",
    "#### ✅ Q3: How are lab tests linked to admissions?\n",
    "**Answer:** Via `hadm_id` (hospital admission ID)\n",
    "- Each lab result has a `hadm_id` linking to `admissions.hadm_id`\n",
    "- This enables temporal analysis relative to admission time\n",
    "- Can filter labs to specific time windows (e.g., first 24 hours)\n",
    "\n",
    "### Table Relationships\n",
    "\n",
    "```\n",
    "Patients → Admissions → Diagnoses\n",
    "                     → ICU Stays\n",
    "                     → Lab Events → Lab Item Descriptions\n",
    "                                 → CBC Features\n",
    "```\n",
    "\n",
    "**Primary Keys:**\n",
    "- `subject_id` - Patient identifier (across all tables)\n",
    "- `hadm_id` - Hospital admission ID (links admissions, diagnoses, labs, ICU)\n",
    "- `itemid` - Lab test identifier (links lab results to test definitions)\n",
    "\n",
    "### Sample Query Patterns Documented\n",
    "\n",
    "The notebook includes 6 production-ready query patterns:\n",
    "1. Get all CBC results for a patient\n",
    "2. Link admissions to diagnoses with descriptions\n",
    "3. Find patients with specific disease (by ICD code)\n",
    "4. Get CBC values within time window of admission\n",
    "5. Build patient-level feature matrix for ML\n",
    "6. Create comprehensive joined dataset\n",
    "\n",
    "### Next Steps for Pipeline Development\n",
    "\n",
    "1. **Data Acquisition**\n",
    "   - Run `scripts/download_mimic_from_bigquery.py` to download MIMIC-IV data\n",
    "   - Or create sample/synthetic data for testing\n",
    "\n",
    "2. **Data Preprocessing** (Issue #5)\n",
    "   - Implement preprocessing pipeline in `src/data/preprocessor.py`\n",
    "   - Handle missing values and outliers\n",
    "   - Standardize units across measurements\n",
    "\n",
    "3. **Feature Engineering** (Issue #6)\n",
    "   - Aggregate CBC values per patient/admission\n",
    "   - Create temporal features (trends, changes over time)\n",
    "   - Generate biomarker labels using threshold generators\n",
    "\n",
    "4. **Model Development**\n",
    "   - Build baseline classifiers for disease prediction\n",
    "   - Evaluate biomarker performance\n",
    "   - Compare literature-based vs data-driven thresholds\n",
    "\n",
    "### Configuration Files Available\n",
    "\n",
    "- `configs/cbc_features.yaml` - CBC feature definitions with reference ranges\n",
    "- `configs/diseases.yaml` - Target diseases with ICD-9/ICD-10 codes\n",
    "\n",
    "### Notes\n",
    "\n",
    "- This documentation is based on the MIMIC-IV 3.1 schema\n",
    "- Actual data must be downloaded separately (requires PhysioNet credentialed access)\n",
    "- The notebook is designed to work with or without data present\n",
    "- All analysis cells include conditional checks for data availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values in CBC labs:\")\n",
    "print(cbc_labs.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for outliers\n",
    "print(\"\\nPotential outliers (beyond 3 std):\")\n",
    "for feature in cbc_labs['feature_name'].unique():\n",
    "    data = cbc_labs[cbc_labs['feature_name'] == feature]['valuenum']\n",
    "    mean, std = data.mean(), data.std()\n",
    "    outliers = ((data < mean - 3*std) | (data > mean + 3*std)).sum()\n",
    "    pct = 100 * outliers / len(data)\n",
    "    print(f\"  {feature}: {outliers:,} ({pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Implement data preprocessing pipeline\n",
    "2. Create patient-level feature aggregation\n",
    "3. Generate biomarker labels using threshold generators\n",
    "4. Build baseline prediction models"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}